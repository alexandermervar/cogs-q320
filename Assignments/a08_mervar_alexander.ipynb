{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A08 Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be an optional homework. Use this implementation of an Artificial Neural Network or a variant created by you and get it to solve a problem. The problem could be as simple as a logic XOR, like we tried to do in class. Alternatively, it could be a more complex problem, like digit recognition or even serving as a controller for a Braitenberg vehicle that finds the light. In the case of solving a logic function like XOR, you should be able to find the parameters of the neural network by hand - with some tweaking. For anything more complicated, you are going to find a way to use an algorithm to train the neural network. One option is to use the Evolutionary Algorithm that you already learned about in a previous assignment. You would make the genotype the parameters and the fitness how good that neural network is at solving the problem. You could also use a Backpropagation algorithm. Or you could even use a stochastic hill-climbing algorithm, where you start with randomly chosen weights, see the fitness, then generate a variation of the current weights, and only adopt the variation if the fitness of that variation is better; discard it if it's worse and generate a new one. Report your findings. This is a 100% open-ended and optional assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    \n",
    "    def __init__(self,NI,NH,NO):\n",
    "        self.nI = NI\n",
    "        self.nH = NH\n",
    "        self.nO = NO\n",
    "        # Parameters of this NN\n",
    "        self.wIH = np.random.random(size=(NI,NH))\n",
    "        self.wHO = np.random.random(size=(NH,NO))\n",
    "        self.bH = np.random.random(size=NH)\n",
    "        self.bO = np.random.random(size=NO) \n",
    "        # State of NN\n",
    "        self.I = np.zeros(NI)\n",
    "        self.H = np.zeros(NH)\n",
    "        self.O = np.zeros(NO)\n",
    "        \n",
    "    def calc(self, inputvector):\n",
    "        self.I = inputvector\n",
    "        for h in range(self.nH):\n",
    "            netinput = self.bH[h]\n",
    "            for i in range(self.nI):\n",
    "                netinput += self.I[i] * self.wIH[i,h]\n",
    "            self.H[h] = sigmoid(netinput)\n",
    "        for o in range(self.nO):\n",
    "            netinput = self.bO[o]            \n",
    "            for h in range(self.nH):\n",
    "                netinput += self.H[h] * self.wHO[h,o]\n",
    "            self.O[o] = sigmoid(netinput)\n",
    "        return self.O\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network goals (targets) here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to implement automatic search for neural networks which \n",
    "# fit to the goal\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
